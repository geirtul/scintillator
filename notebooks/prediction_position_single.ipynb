{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of origin for single electron event\n",
    "This notebook aims to build a model able to predict where a single electron event originated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image data shape: (10000, 16, 16, 1)\n",
      "Energies shape: (10000,)\n",
      "Positions shape: (10000, 2)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here are the data files.  For all data files each image and label is on one row.  \n",
    "The first 256 values in each row correspond to the 16x16 detector image and \n",
    "the last 6 values correspond to Energy1, Xpos1, Ypos1, Energy2, Xpos2, Ypos2.  \n",
    "If there is no second particle then Energy2 = 0 and Xpos2 and Ypos2 are both -100.  \n",
    "(When I run my model, I have to reset the -100 to 0).\n",
    " \n",
    "CeBr10kSingle are 10,000 rows of data and labels for single interactions in the detector\n",
    "CeBr10k_1.txt is 10,000 rows of data and labels with a mix of single interactions and double interactions\n",
    "CeBr10.txt is a small file I use which contains 10 single interactions.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# File import\n",
    "PATH = \"../data/small_sample/\"\n",
    "filenames = [\"CeBr10kSingle_1.txt\", \"CeBr10kSingle_2.txt\", \"CeBr10k_1.txt\", \"CeBr10.txt\"]\n",
    "\n",
    "## single, mix, small define which dataset to load.\n",
    "file_to_load = \"single_1\"\n",
    "\n",
    "if file_to_load == \"single_1\":\n",
    "    infile = PATH+filenames[0]\n",
    "if file_to_load == \"single_2\":\n",
    "    infile = PATH+filenames[1]\n",
    "if file_to_load == \"mix\":\n",
    "    infile = PATH+filenames[2]\n",
    "if file_to_load == \"small\":\n",
    "    infile = PATH+filenames[3]\n",
    "\n",
    "\n",
    "data = np.loadtxt(infile)\n",
    "n_pixels = data.shape[1] - 6 # the six params at the end are not part of the image\n",
    "n_img = data.shape[0]\n",
    "images = data[:, :n_pixels].reshape(n_img, 16, 16, 1)# reshape to image dims (batch, rows, cols, channels)\n",
    "images = np.transpose(images, axes=[0, 2, 1, 3]) # transpose to correct spatial orientation\n",
    "energy_pos = data[:, n_pixels:] # Energy1, Xpos1, Ypos1, Energy2, Xpos2, Ypos2\n",
    "\n",
    "print(\"Image data shape: {}\".format(images.shape))\n",
    "\n",
    "if file_to_load in [\"single_1\", \"single_2\"]:\n",
    "    energy = energy_pos[:,0]\n",
    "    position = energy_pos[:,1:3]\n",
    "    print(\"Energies shape: {}\".format(energy.shape))\n",
    "    print(\"Positions shape: {}\".format(position.shape))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Set up training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and test data shapes:\n",
      "x_train: (7000, 16, 16, 1)\n",
      "x_test: (3000, 16, 16, 1)\n",
      "y_train: (7000, 2)\n",
      "y_test: (3000, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, position, test_size = 0.3)\n",
    "print(\"Training and test data shapes:\")\n",
    "print(\"x_train: {}\".format(x_train.shape))\n",
    "print(\"x_test: {}\".format(x_test.shape))\n",
    "print(\"y_train: {}\".format(y_train.shape))\n",
    "print(\"y_test: {}\".format(y_test.shape))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and compile model\n",
    "Using Keras as our framework with Tensorflow backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# Parameters for the model\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Set up sequetial model based on Keras CIFAR-10 example\n",
    "model = Sequential()\n",
    "\n",
    "# Add layers\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "#model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Conv2D(64, (3, 3)))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(512))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='mse',\n",
    "              optimizer='adam',\n",
    "              metrics=[])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      " 480/7000 [=>............................] - ETA: 3s - loss: 610.8555 "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test-set and plot some examples\n",
    "To compare predicted positions with actual positions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_pos = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot some images, with electron origin positions\n",
    "%matplotlib inline\n",
    "\n",
    "index = 100\n",
    "fig, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(12,12))\n",
    "\n",
    "# Reshape test-data for plotting\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2])\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        # plot image\n",
    "        ax[i, j].imshow(x_test[index + i*3 + j])\n",
    "        \n",
    "        # plot true origin of event\n",
    "        x = y_test[index + i*3 + j][0]\n",
    "        y = y_test[index + i*3 + j][1]\n",
    "        ax[i, j].plot(x, y, 'rx')\n",
    "        \n",
    "        # plot predicted origin of event\n",
    "        x_pred = predicted_pos[index + i*3 + j][0]\n",
    "        y_pred = predicted_pos[index + i*3 + j][1]\n",
    "        ax[i, j].plot(x_pred, y_pred, 'wx')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
