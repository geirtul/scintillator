{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificiation of single and double events\n",
    "This notebook aims to build a model capable of classifying single and double events in a mixed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image data shape: (10000, 16, 16, 1)\n",
      "Energies shape: (10000, 2)\n",
      "Positions shape: (10000, 4)\n",
      "Labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here are the data files.  For all data files each image and label is on one row.  \n",
    "The first 256 values in each row correspond to the 16x16 detector image and \n",
    "the last 6 values correspond to Energy1, Xpos1, Ypos1, Energy2, Xpos2, Ypos2.  \n",
    "If there is no second particle then Energy2 = 0 and Xpos2 and Ypos2 are both -100.  \n",
    "(When I run my model, I have to reset the -100 to 0).\n",
    " \n",
    "CeBr10kSingle are 10,000 rows of data and labels for single interactions in the detector\n",
    "CeBr10k_1.txt is 10,000 rows of data and labels with a mix of single interactions and double interactions\n",
    "CeBr10.txt is a small file I use which contains 10 single interactions.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from data_functions import separate_simulated_data, label_simulated_data\n",
    "\n",
    "# File import\n",
    "PATH = \"../data/small_sample/\"\n",
    "filenames = [\"CeBr10kSingle_1.txt\", \"CeBr10kSingle_2.txt\", \"CeBr10k_1.txt\", \"CeBr10.txt\"]\n",
    "\n",
    "## single, mix, small define which dataset to load.\n",
    "file_to_load = \"mix\"\n",
    "\n",
    "if file_to_load == \"single_1\":\n",
    "    infile = PATH+filenames[0]\n",
    "if file_to_load == \"single_2\":\n",
    "    infile = PATH+filenames[1]\n",
    "if file_to_load == \"mix\":\n",
    "    infile = PATH+filenames[2]\n",
    "if file_to_load == \"small\":\n",
    "    infile = PATH+filenames[3]\n",
    "if file_to_load == \"combined_single\":\n",
    "    infile = PATH+filenames[0]\n",
    "    infile2 = PATH+filenames[1]\n",
    "\n",
    "data = np.loadtxt(infile)\n",
    "\n",
    "if file_to_load == \"combined_single\":\n",
    "    data2 = np.loadtxt(infile2)\n",
    "    data = np.concatenate((data, data2))\n",
    "    \n",
    "images, energies, positions = separate_simulated_data(data)\n",
    "labels = label_simulated_data(energies)\n",
    "\n",
    "\n",
    "print(\"Image data shape: {}\".format(images.shape))\n",
    "print(\"Energies shape: {}\".format(energies.shape))\n",
    "print(\"Positions shape: {}\".format(positions.shape))\n",
    "print(\"Labels shape: {}\".format(labels.shape))\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Set up training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, energies, test_size = 0.2)\n",
    "print(\"Training and test data shapes:\")\n",
    "print(\"x_train: {}\".format(x_train.shape))\n",
    "print(\"x_test: {}\".format(x_test.shape))\n",
    "print(\"y_train: {}\".format(y_train.shape))\n",
    "print(\"y_test: {}\".format(y_test.shape))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and compile model\n",
    "Using Keras as our framework with Tensorflow backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend\n",
    "\n",
    "# Set up sequetial model based on Keras CIFAR-10 example\n",
    "model = Sequential()\n",
    "\n",
    "# Add layers\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Conv2D(32, (3, 3)))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "#model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Conv2D(64, (3, 3)))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(128))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='cross-entropy',\n",
    "              optimizer='adam',\n",
    "              metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "We also output the mean squared error and R2-score as evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameters for the model\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    validation_data=(x_test, y_test), \n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot history of metrics on training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.plot(history.history['r2_keras'])\n",
    "plt.plot(history.history['val_r2_keras'])\n",
    "plt.title('model R2 score')\n",
    "plt.ylabel('R2 score')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss (mse)')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
